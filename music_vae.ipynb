{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install magenta==2.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W-jBLwb3sDpc",
        "outputId": "9032f9f7-cba4-4314-d0c7-950927d827f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting magenta==2.1.0\n",
            "  Downloading magenta-2.1.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 9.7 MB/s \n",
            "\u001b[?25hCollecting python-rtmidi<1.2,>=1.1\n",
            "  Downloading python-rtmidi-1.1.2.tar.gz (204 kB)\n",
            "\u001b[K     |████████████████████████████████| 204 kB 52.6 MB/s \n",
            "\u001b[?25hCollecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=3.4.2 in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (7.1.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (2.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (0.37.1)\n",
            "Collecting mido==1.2.6\n",
            "  Downloading mido-1.2.6-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting sk-video\n",
            "  Downloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 47.6 MB/s \n",
            "\u001b[?25hCollecting note-seq\n",
            "  Downloading note_seq-0.0.5-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 42.0 MB/s \n",
            "\u001b[?25hCollecting dm-sonnet\n",
            "  Downloading dm_sonnet-2.0.0-py3-none-any.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 65.5 MB/s \n",
            "\u001b[?25hCollecting numba<0.50\n",
            "  Downloading numba-0.49.1-cp37-cp37m-manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 45.6 MB/s \n",
            "\u001b[?25hCollecting pretty-midi>=0.2.6\n",
            "  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 40.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (1.3.0)\n",
            "Collecting mir-eval>=0.4\n",
            "  Downloading mir_eval-0.7.tar.gz (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (2.9.2)\n",
            "Collecting pygtrie>=2.3\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: librosa>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (1.7.3)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (4.6.0)\n",
            "Collecting sox>=1.3.7\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Collecting apache-beam[gcp]>=2.14.0\n",
            "  Downloading apache_beam-2.42.0-cp37-cp37m-manylinux2010_x86_64.whl (11.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 41.6 MB/s \n",
            "\u001b[?25hCollecting tensor2tensor\n",
            "  Downloading tensor2tensor-1.15.7-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=1.5.3 in /usr/local/lib/python3.7/dist-packages (from magenta==2.1.0) (3.2.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2022.5)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.50.0)\n",
            "Requirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (0.17.4)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 48.4 MB/s \n",
            "\u001b[?25hCollecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 50.7 MB/s \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (506 kB)\n",
            "\u001b[K     |████████████████████████████████| 506 kB 57.5 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0,>=2.24.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 51.9 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.22.1-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (3.17.3)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2022.6.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (4.1.1)\n",
            "Collecting cloudpickle~=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.7)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (6.0.1)\n",
            "Requirement already satisfied: google-cloud-bigquery<3,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.21.0)\n",
            "Collecting google-cloud-bigquery-storage<2.14,>=2.6.3\n",
            "  Downloading google_cloud_bigquery_storage-2.13.2-py2.py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 59.2 MB/s \n",
            "\u001b[?25hCollecting google-cloud-vision<2,>=0.38.0\n",
            "  Downloading google_cloud_vision-1.0.2-py2.py3-none-any.whl (435 kB)\n",
            "\u001b[K     |████████████████████████████████| 435 kB 46.0 MB/s \n",
            "\u001b[?25hCollecting google-cloud-recommendations-ai<0.8.0,>=0.1.0\n",
            "  Downloading google_cloud_recommendations_ai-0.7.1-py2.py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 58.7 MB/s \n",
            "\u001b[?25hCollecting google-cloud-dlp<4,>=3.0.0\n",
            "  Downloading google_cloud_dlp-3.9.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 44.5 MB/s \n",
            "\u001b[?25hCollecting google-apitools<0.5.32,>=0.5.31\n",
            "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
            "\u001b[K     |████████████████████████████████| 173 kB 48.5 MB/s \n",
            "\u001b[?25hCollecting google-cloud-spanner<2,>=1.13.0\n",
            "  Downloading google_cloud_spanner-1.19.3-py2.py3-none-any.whl (255 kB)\n",
            "\u001b[K     |████████████████████████████████| 255 kB 46.0 MB/s \n",
            "\u001b[?25hCollecting google-auth-httplib2<0.2.0,>=0.1.0\n",
            "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting google-cloud-videointelligence<2,>=1.8.0\n",
            "  Downloading google_cloud_videointelligence-1.16.3-py2.py3-none-any.whl (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools<5,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (4.2.4)\n",
            "Requirement already satisfied: google-cloud-core<3,>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.0.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.35.0)\n",
            "Collecting google-cloud-language<2,>=1.3.0\n",
            "  Downloading google_cloud_language-1.3.2-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-datastore<2,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.8.0)\n",
            "Collecting google-cloud-pubsub<3,>=2.1.0\n",
            "  Downloading google_cloud_pubsub-2.13.10-py2.py3-none-any.whl (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 56.9 MB/s \n",
            "\u001b[?25hCollecting grpcio-gcp<1,>=0.2.2\n",
            "  Downloading grpcio_gcp-0.2.2-py2.py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: google-api-core!=2.8.2,<3 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.31.6)\n",
            "Collecting google-cloud-pubsublite<2,>=1.2.0\n",
            "  Downloading google_cloud_pubsublite-1.6.0-py2.py3-none-any.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 67.4 MB/s \n",
            "\u001b[?25hCollecting google-cloud-bigtable<2,>=0.31.1\n",
            "  Downloading google_cloud_bigtable-1.7.2-py2.py3-none-any.whl (267 kB)\n",
            "\u001b[K     |████████████████████████████████| 267 kB 69.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.8.2,<3->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.56.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.8.2,<3->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core!=2.8.2,<3->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (21.3)\n",
            "Collecting fasteners>=0.14\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (4.1.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (4.9)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (0.4.1)\n",
            "Collecting protobuf<4,>=3.12.2\n",
            "  Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 45.0 MB/s \n",
            "\u001b[?25hCollecting google-cloud-core<3,>=0.28.1\n",
            "  Downloading google_cloud_core-1.7.3-py2.py3-none-any.whl (28 kB)\n",
            "Collecting grpc-google-iam-v1<0.13dev,>=0.12.3\n",
            "  Downloading grpc_google_iam_v1-0.12.4-py2.py3-none-any.whl (26 kB)\n",
            "Collecting google-cloud-dlp<4,>=3.0.0\n",
            "  Downloading google_cloud_dlp-3.9.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 54.9 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_dlp-3.9.0-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 66.1 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_dlp-3.8.1-py2.py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 56.3 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_dlp-3.8.0-py2.py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 44.9 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_dlp-3.7.1-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 63.6 MB/s \n",
            "\u001b[?25hCollecting grpcio-status>=1.16.0\n",
            "  Downloading grpcio_status-1.50.0-py3-none-any.whl (14 kB)\n",
            "Collecting google-cloud-pubsub<3,>=2.1.0\n",
            "  Downloading google_cloud_pubsub-2.13.9-py2.py3-none-any.whl (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 63.1 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_pubsub-2.13.8-py2.py3-none-any.whl (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 50.1 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_pubsub-2.13.7-py2.py3-none-any.whl (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 55.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_pubsub-2.13.6-py2.py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 40.9 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_pubsub-2.13.5-py2.py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 50.9 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_pubsub-2.13.4-py2.py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 58.4 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_pubsub-2.13.3-py2.py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 56.0 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_pubsub-2.13.2-py2.py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 44.4 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_pubsub-2.13.1-py2.py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 49.8 MB/s \n",
            "\u001b[?25hCollecting google-cloud-pubsublite<2,>=1.2.0\n",
            "  Downloading google_cloud_pubsublite-1.5.0-py2.py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 64.8 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_pubsublite-1.4.3-py2.py3-none-any.whl (267 kB)\n",
            "\u001b[K     |████████████████████████████████| 267 kB 51.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_pubsublite-1.4.2-py2.py3-none-any.whl (265 kB)\n",
            "\u001b[K     |████████████████████████████████| 265 kB 49.9 MB/s \n",
            "\u001b[?25hCollecting overrides<7.0.0,>=6.0.1\n",
            "  Downloading overrides-6.5.0-py3-none-any.whl (17 kB)\n",
            "Collecting google-cloud-recommendations-ai<0.8.0,>=0.1.0\n",
            "  Downloading google_cloud_recommendations_ai-0.7.0-py2.py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 62.7 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_recommendations_ai-0.6.2-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 72.0 MB/s \n",
            "\u001b[?25hCollecting grpcio-status>=1.16.0\n",
            "  Downloading grpcio_status-1.49.1-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (1.0.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (0.11.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (1.2.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (1.6.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (0.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (3.0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.3->magenta==2.1.0) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.3->magenta==2.1.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.3->magenta==2.1.0) (1.4.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir-eval>=0.4->magenta==2.1.0) (0.16.0)\n",
            "Collecting llvmlite<=0.33.0.dev0,>=0.31.0.dev0\n",
            "  Downloading llvmlite-0.32.1-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=1.4.12->google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.6.2->magenta==2.1.0) (1.4.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.24.3)\n",
            "Collecting resampy>=0.2.2\n",
            "  Downloading resampy-0.4.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 46.3 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.4.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 66.1 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.6.2->magenta==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.6.2->magenta==2.1.0) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.6.2->magenta==2.1.0) (2.21)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->magenta==2.1.0) (0.8.10)\n",
            "Requirement already satisfied: dm-tree>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->magenta==2.1.0) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from dm-sonnet->magenta==2.1.0) (1.14.1)\n",
            "Requirement already satisfied: bokeh>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from note-seq->magenta==2.1.0) (2.3.3)\n",
            "Requirement already satisfied: intervaltree>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from note-seq->magenta==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from note-seq->magenta==2.1.0) (7.9.0)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting note-seq\n",
            "  Downloading note_seq-0.0.4-py3-none-any.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 48.6 MB/s \n",
            "\u001b[?25h  Downloading note_seq-0.0.3-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from note-seq->magenta==2.1.0) (22.1.0)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from note-seq->magenta==2.1.0) (1.3.5)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh>=0.12.0->note-seq->magenta==2.1.0) (2.11.3)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=0.12.0->note-seq->magenta==2.1.0) (5.1.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh>=0.12.0->note-seq->magenta==2.1.0) (6.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from intervaltree>=2.1.0->note-seq->magenta==2.1.0) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh>=0.12.0->note-seq->magenta==2.1.0) (2.0.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->note-seq->magenta==2.1.0) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->note-seq->magenta==2.1.0) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->note-seq->magenta==2.1.0) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython->note-seq->magenta==2.1.0) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->note-seq->magenta==2.1.0) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython->note-seq->magenta==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython->note-seq->magenta==2.1.0) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->note-seq->magenta==2.1.0) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->note-seq->magenta==2.1.0) (0.7.0)\n",
            "Collecting tensorflow-probability\n",
            "  Downloading tensorflow_probability-0.7.0-py2.py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->magenta==2.1.0) (4.64.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->magenta==2.1.0) (1.1.4)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->magenta==2.1.0) (0.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->magenta==2.1.0) (1.7.1)\n",
            "Collecting pypng\n",
            "  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dopamine-rl in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->magenta==2.1.0) (1.0.5)\n",
            "Collecting mesh-tensorflow\n",
            "  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
            "\u001b[K     |████████████████████████████████| 385 kB 56.7 MB/s \n",
            "\u001b[?25hCollecting gevent\n",
            "  Downloading gevent-22.10.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 42.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->magenta==2.1.0) (1.12.11)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->magenta==2.1.0) (3.1.0)\n",
            "Collecting bz2file\n",
            "  Downloading bz2file-0.98.tar.gz (11 kB)\n",
            "Collecting kfac\n",
            "  Downloading kfac-0.2.4-py2.py3-none-any.whl (193 kB)\n",
            "\u001b[K     |████████████████████████████████| 193 kB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->magenta==2.1.0) (4.6.0.66)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from tensor2tensor->magenta==2.1.0) (0.25.2)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-gan\n",
            "  Downloading tensorflow_gan-2.1.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym->tensor2tensor->magenta==2.1.0) (4.13.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym->tensor2tensor->magenta==2.1.0) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->tensor2tensor->magenta==2.1.0) (3.10.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor->magenta==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor->magenta==2.1.0) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->tensor2tensor->magenta==2.1.0) (1.0.1)\n",
            "Collecting zope.event\n",
            "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting greenlet>=2.0.0\n",
            "  Downloading greenlet-2.0.0.post0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511 kB)\n",
            "\u001b[K     |████████████████████████████████| 511 kB 56.2 MB/s \n",
            "\u001b[?25hCollecting zope.interface\n",
            "  Downloading zope.interface-5.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 56.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->tensor2tensor->magenta==2.1.0) (3.0.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->tensor2tensor->magenta==2.1.0) (1.5.2)\n",
            "Collecting h5py\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 47.4 MB/s \n",
            "\u001b[?25hCollecting kfac\n",
            "  Downloading kfac-0.2.3-py2.py3-none-any.whl (191 kB)\n",
            "\u001b[K     |████████████████████████████████| 191 kB 69.0 MB/s \n",
            "\u001b[?25h  Downloading kfac-0.2.2-py2.py3-none-any.whl (191 kB)\n",
            "\u001b[K     |████████████████████████████████| 191 kB 52.4 MB/s \n",
            "\u001b[?25h  Downloading kfac-0.2.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->tensor2tensor->magenta==2.1.0) (1.2.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (2.9.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (0.4.0)\n",
            "Collecting protobuf<4,>=3.12.2\n",
            "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (2.9.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (2.0.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (0.27.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (1.12)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (14.0.6)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->magenta==2.1.0) (1.1.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (3.4.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (3.2.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tensor2tensor->magenta==2.1.0) (2.7.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->magenta==2.1.0) (0.10.2)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->magenta==2.1.0) (0.8.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->magenta==2.1.0) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->magenta==2.1.0) (5.10.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->magenta==2.1.0) (1.10.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gan->tensor2tensor->magenta==2.1.0) (0.12.0)\n",
            "Building wheels for collected packages: dill, google-apitools, mir-eval, pretty-midi, python-rtmidi, docopt, bz2file\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=284750cda3127cd1f9bc9b7484813c7dc09f031396cb4b06e47e4cd7a43d8839\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131039 sha256=eebb9bcde5c163e89ae89106015282806033808fa67625d570a8f74b63e0f66d\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/b5/2f/1cc3cf2b31e7a9cd1508731212526d9550271274d351c96f16\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-eval: filename=mir_eval-0.7-py3-none-any.whl size=100721 sha256=7920d5130a24a621b957db98a07e0980a8dbeaf837ec3a53aa79b6f9c4ced027\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/5a/46/d2527ff1fd975e1a793375e6ed763bfe4d3ea396b7cdc470eb\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591955 sha256=0c306c9b2e685c5a367c195994811f1a6d10338ab4aa89bf8c6425a31152d798\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/74/7c/a06473ca8dcb63efb98c1e67667ce39d52100f837835ea18fa\n",
            "  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-rtmidi: filename=python_rtmidi-1.1.2-cp37-cp37m-linux_x86_64.whl size=391740 sha256=dd0ac673c197995d5f519aed6c26af088e5d274ba51426873ea07ff488d494ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/0c/e1/ccca9af1590f715067166c3199f6b639a26a152f61d4e79397\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=aa423b473fb33cd5f00c933e37d5d3b0e50ed52ffef450b4f813a403983bed7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bz2file: filename=bz2file-0.98-py3-none-any.whl size=6882 sha256=e77907bf48dfb46a63e31e4673adaa0df942e07da550847cb7d42519d77b9f4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/ce/8d/b5f76b602b16a8a39f2ded74189cf5f09fc4a87bea16c54a8b\n",
            "Successfully built dill google-apitools mir-eval pretty-midi python-rtmidi docopt bz2file\n",
            "Installing collected packages: protobuf, requests, llvmlite, proto-plus, numba, grpcio-status, grpcio-gcp, grpc-google-iam-v1, docopt, cloudpickle, zstandard, zope.interface, zope.event, tensorflow-probability, resampy, pymongo, overrides, orjson, mido, jedi, hdfs, greenlet, google-cloud-pubsub, google-cloud-core, google-auth-httplib2, fasteners, fastavro, dill, tf-slim, tensorflow-gan, tensorflow-addons, pypng, pydub, pretty-midi, mesh-tensorflow, kfac, gunicorn, google-cloud-vision, google-cloud-videointelligence, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-pubsublite, google-cloud-language, google-cloud-dlp, google-cloud-bigtable, google-cloud-bigquery-storage, google-apitools, gevent, bz2file, apache-beam, tensor2tensor, sox, sk-video, python-rtmidi, pygtrie, note-seq, mir-eval, dm-sonnet, magenta\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.3\n",
            "    Uninstalling numba-0.56.3:\n",
            "      Successfully uninstalled numba-0.56.3\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.16.0\n",
            "    Uninstalling tensorflow-probability-0.16.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.16.0\n",
            "  Attempting uninstall: resampy\n",
            "    Found existing installation: resampy 0.4.2\n",
            "    Uninstalling resampy-0.4.2:\n",
            "      Successfully uninstalled resampy-0.4.2\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.2\n",
            "    Uninstalling pymongo-4.3.2:\n",
            "      Successfully uninstalled pymongo-4.3.2\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 1.1.3.post0\n",
            "    Uninstalling greenlet-1.1.3.post0:\n",
            "      Successfully uninstalled greenlet-1.1.3.post0\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: google-auth-httplib2\n",
            "    Found existing installation: google-auth-httplib2 0.0.4\n",
            "    Uninstalling google-auth-httplib2-0.0.4:\n",
            "      Successfully uninstalled google-auth-httplib2-0.0.4\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: google-cloud-language\n",
            "    Found existing installation: google-cloud-language 1.2.0\n",
            "    Uninstalling google-cloud-language-1.2.0:\n",
            "      Successfully uninstalled google-cloud-language-1.2.0\n",
            "  Attempting uninstall: google-cloud-bigquery-storage\n",
            "    Found existing installation: google-cloud-bigquery-storage 1.1.2\n",
            "    Uninstalling google-cloud-bigquery-storage-1.1.2:\n",
            "      Successfully uninstalled google-cloud-bigquery-storage-1.1.2\n",
            "Successfully installed apache-beam-2.42.0 bz2file-0.98 cloudpickle-2.1.0 dill-0.3.1.1 dm-sonnet-2.0.0 docopt-0.6.2 fastavro-1.7.0 fasteners-0.18 gevent-22.10.2 google-apitools-0.5.31 google-auth-httplib2-0.1.0 google-cloud-bigquery-storage-2.13.2 google-cloud-bigtable-1.7.2 google-cloud-core-1.7.3 google-cloud-dlp-3.7.1 google-cloud-language-1.3.2 google-cloud-pubsub-2.13.1 google-cloud-pubsublite-1.4.2 google-cloud-recommendations-ai-0.6.2 google-cloud-spanner-1.19.3 google-cloud-videointelligence-1.16.3 google-cloud-vision-1.0.2 greenlet-2.0.0.post0 grpc-google-iam-v1-0.12.4 grpcio-gcp-0.2.2 grpcio-status-1.48.2 gunicorn-20.1.0 hdfs-2.7.0 jedi-0.18.1 kfac-0.2.0 llvmlite-0.32.1 magenta-2.1.0 mesh-tensorflow-0.1.21 mido-1.2.6 mir-eval-0.7 note-seq-0.0.3 numba-0.49.1 orjson-3.8.1 overrides-6.5.0 pretty-midi-0.2.9 proto-plus-1.22.1 protobuf-3.19.6 pydub-0.25.1 pygtrie-2.5.0 pymongo-3.13.0 pypng-0.20220715.0 python-rtmidi-1.1.2 requests-2.28.1 resampy-0.3.1 sk-video-1.1.10 sox-1.4.1 tensor2tensor-1.15.7 tensorflow-addons-0.18.0 tensorflow-gan-2.1.0 tensorflow-probability-0.7.0 tf-slim-1.1.0 zope.event-4.5.0 zope.interface-5.5.1 zstandard-0.19.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 전처리"
      ],
      "metadata": {
        "id": "mxIzLxN3pQwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# 데이터 불러오기 및 압축 풀기\n",
        "dir = '/content/data/groove-v1.0.0-midionly.zip'\n",
        "zipfile.ZipFile(dir).extractall()"
      ],
      "metadata": {
        "id": "7T3ZIiWp4-jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# info.csv를 확인\n",
        "df = pd.read_csv('/content/groove/info.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "MCRN5iyjcQOk",
        "outputId": "03aa6c6c-cc7a-4d01-dc36-42d8f8292d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    drummer                session                        id          style  \\\n",
              "0  drummer1  drummer1/eval_session   drummer1/eval_session/1   funk/groove1   \n",
              "1  drummer1  drummer1/eval_session  drummer1/eval_session/10  soul/groove10   \n",
              "2  drummer1  drummer1/eval_session   drummer1/eval_session/2   funk/groove2   \n",
              "3  drummer1  drummer1/eval_session   drummer1/eval_session/3   soul/groove3   \n",
              "4  drummer1  drummer1/eval_session   drummer1/eval_session/4   soul/groove4   \n",
              "\n",
              "   bpm beat_type time_signature  \\\n",
              "0  138      beat            4-4   \n",
              "1  102      beat            4-4   \n",
              "2  105      beat            4-4   \n",
              "3   86      beat            4-4   \n",
              "4   80      beat            4-4   \n",
              "\n",
              "                                       midi_filename  \\\n",
              "0  drummer1/eval_session/1_funk-groove1_138_beat_...   \n",
              "1  drummer1/eval_session/10_soul-groove10_102_bea...   \n",
              "2  drummer1/eval_session/2_funk-groove2_105_beat_...   \n",
              "3  drummer1/eval_session/3_soul-groove3_86_beat_4...   \n",
              "4  drummer1/eval_session/4_soul-groove4_80_beat_4...   \n",
              "\n",
              "                                      audio_filename   duration split  \n",
              "0  drummer1/eval_session/1_funk-groove1_138_beat_...  27.872308  test  \n",
              "1  drummer1/eval_session/10_soul-groove10_102_bea...  37.691158  test  \n",
              "2  drummer1/eval_session/2_funk-groove2_105_beat_...  36.351218  test  \n",
              "3  drummer1/eval_session/3_soul-groove3_86_beat_4...  44.716543  test  \n",
              "4  drummer1/eval_session/4_soul-groove4_80_beat_4...  47.987500  test  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b195d10b-f369-4e0a-a7fe-019df8fcb55b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drummer</th>\n",
              "      <th>session</th>\n",
              "      <th>id</th>\n",
              "      <th>style</th>\n",
              "      <th>bpm</th>\n",
              "      <th>beat_type</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>midi_filename</th>\n",
              "      <th>audio_filename</th>\n",
              "      <th>duration</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/1</td>\n",
              "      <td>funk/groove1</td>\n",
              "      <td>138</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
              "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
              "      <td>27.872308</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/10</td>\n",
              "      <td>soul/groove10</td>\n",
              "      <td>102</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
              "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
              "      <td>37.691158</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/2</td>\n",
              "      <td>funk/groove2</td>\n",
              "      <td>105</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
              "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
              "      <td>36.351218</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/3</td>\n",
              "      <td>soul/groove3</td>\n",
              "      <td>86</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
              "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
              "      <td>44.716543</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/4</td>\n",
              "      <td>soul/groove4</td>\n",
              "      <td>80</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
              "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
              "      <td>47.987500</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b195d10b-f369-4e0a-a7fe-019df8fcb55b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b195d10b-f369-4e0a-a7fe-019df8fcb55b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b195d10b-f369-4e0a-a7fe-019df8fcb55b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from magenta.scripts.convert_dir_to_note_sequences import convert_directory\n",
        "\n",
        "# convert_directory 함수를 이용하여 midi 파일을 tfrecord 파일로 변환\n",
        "root_dir = '/content/groove'\n",
        "output_file = '/content/data/tfrecord'\n",
        "\n",
        "convert_directory(root_dir, output_file, recursive=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4ke_m2Xftx9",
        "outputId": "94bbe16b-c69b-4a93-c74d-c76609f61519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/info.csv\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/README\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/LICENSE\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer5/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer5/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer5/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer5/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer9/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer9/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer8/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer8/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer8/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer8/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer10/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer10/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer2/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer2/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer2/session3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer1/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer1/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer1/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer1/session3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer7/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer7/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer7/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer7/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer7/session3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer3/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer3/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer4/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer4/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer6/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer6/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer6/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file /content/groove/drummer6/session3/Icon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 모델"
      ],
      "metadata": {
        "id": "PUqIHCcwpXpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from magenta.models.music_vae.configs import Config\n",
        "from magenta.models.music_vae import lstm_models\n",
        "from magenta.models.music_vae import data\n",
        "from magenta.models.music_vae.base_model import MusicVAE\n",
        "from magenta.common import merge_hparams\n",
        "from magenta.contrib.training import HParams\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "Config.__new__.__defaults__ = (None,) * len(Config._fields)\n",
        "CONFIG_MAP = {}\n",
        "HParams = HParams\n",
        "\n",
        "CONFIG_MAP['groovae_4bar'] = Config(\n",
        "    model=MusicVAE(lstm_models.BidirectionalLstmEncoder(),\n",
        "                   lstm_models.GrooveLstmDecoder()),\n",
        "    hparams=merge_hparams(\n",
        "        lstm_models.get_default_hparams(),\n",
        "        HParams(\n",
        "            batch_size=512,\n",
        "            max_seq_len=16 * 4,  # 4 bars w/ 16 steps per bar\n",
        "            z_size=256,\n",
        "            enc_rnn_size=[512],\n",
        "            dec_rnn_size=[256, 256],\n",
        "            max_beta=0.2,\n",
        "            free_bits=48,\n",
        "            dropout_keep_prob=0.3,\n",
        "        )),\n",
        "    note_sequence_augmenter=None,\n",
        "    data_converter=data.GrooveConverter(\n",
        "        split_bars=4, steps_per_quarter=4, quarters_per_bar=4,\n",
        "        max_tensors_per_notesequence=20,\n",
        "        pitch_classes=data.ROLAND_DRUM_PITCH_CLASSES,\n",
        "        inference_pitch_classes=data.REDUCED_DRUM_PITCH_CLASSES),\n",
        "    tfds_name='groove/4bar-midionly',\n",
        ")"
      ],
      "metadata": {
        "id": "QE6FvGwdmuEX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG_MAP\n",
        "# 'Config': ['model', 'hparams', 'note_sequence_augmenter', 'data_converter','train_examples_path', 'eval_examples_path', 'tfds_name']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-GcjmMxd4D_",
        "outputId": "ee54231b-a055-440c-8311-b5a3db3f2a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'groovae_4bar': Config(model=<magenta.models.music_vae.base_model.MusicVAE object at 0x7f8c4c8bff10>, hparams=HParams([('batch_size', 512), ('beta_rate', 0.0), ('clip_mode', 'global_norm'), ('conditional', True), ('control_preprocessing_rnn_size', [256]), ('dec_rnn_size', [256, 256]), ('decay_rate', 0.9999), ('dropout_keep_prob', 0.3), ('enc_rnn_size', [512]), ('free_bits', 48), ('grad_clip', 1.0), ('grad_norm_clip_to_zero', 10000), ('learning_rate', 0.001), ('max_beta', 0.2), ('max_seq_len', 64), ('min_learning_rate', 1e-05), ('residual_decoder', False), ('residual_encoder', False), ('sampling_rate', 0.0), ('sampling_schedule', 'constant'), ('use_cudnn', False), ('z_size', 256)]), note_sequence_augmenter=None, data_converter=<magenta.models.music_vae.data.GrooveConverter object at 0x7f8c4c8bf690>, train_examples_path=None, eval_examples_path=None, tfds_name='groove/4bar-midionly')}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 모델은 지수 감쇠율 0.9999 및 배치 크기 512로 10^-3에서 10^-5로 어닐링된 학습률로 학습 되었습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "4WlvJYbSd6uH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 학습"
      ],
      "metadata": {
        "id": "cyMUNxYJ3U4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae import data\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tf_slim"
      ],
      "metadata": {
        "id": "hbtE7lP8R8yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서보드 요약 로그 저장 함수\n",
        "\n",
        "def _trial_summary(hparams, examples_path, output_dir):\n",
        "  examples_path_summary = tf.summary.text(\n",
        "      'examples_path', tf.constant(examples_path, name='examples_path'),\n",
        "      collections=[])\n",
        "\n",
        "  hparams_dict = hparams.values()\n",
        "\n",
        "  # Create a markdown table from hparams.\n",
        "  header = '| Key | Value |\\n| :--- | :--- |\\n'\n",
        "  keys = sorted(hparams_dict.keys())\n",
        "  lines = ['| %s | %s |' % (key, str(hparams_dict[key])) for key in keys]\n",
        "  hparams_table = header + '\\n'.join(lines) + '\\n'\n",
        "\n",
        "  hparam_summary = tf.summary.text(\n",
        "      'hparams', tf.constant(hparams_table, name='hparams'), collections=[])\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    writer = tf.summary.FileWriter(output_dir, graph=sess.graph)\n",
        "    writer.add_summary(examples_path_summary.eval())\n",
        "    writer.add_summary(hparam_summary.eval())\n",
        "    writer.close()"
      ],
      "metadata": {
        "id": "8M2xeBBWJDaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ilApYmm6_AmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 데이터로 부터 input tensor를 가져오는 함수\n",
        " \n",
        "def _get_input_tensors(dataset, config):\n",
        "\n",
        "  batch_size = config.hparams.batch_size\n",
        "  iterator = tf.data.make_one_shot_iterator(dataset)\n",
        "  (input_sequence, output_sequence, control_sequence,\n",
        "   sequence_length) = iterator.get_next()\n",
        "  input_sequence.set_shape(\n",
        "      [batch_size, None, config.data_converter.input_depth])\n",
        "  output_sequence.set_shape(\n",
        "      [batch_size, None, config.data_converter.output_depth])\n",
        "  if not config.data_converter.control_depth:\n",
        "    control_sequence = None\n",
        "  else:\n",
        "    control_sequence.set_shape(\n",
        "        [batch_size, None, config.data_converter.control_depth])\n",
        "  sequence_length.set_shape([batch_size] + sequence_length.shape[1:].as_list())\n",
        "\n",
        "  return {\n",
        "      'input_sequence': input_sequence,\n",
        "      'output_sequence': output_sequence,\n",
        "      'control_sequence': control_sequence,\n",
        "      'sequence_length': sequence_length\n",
        "  }"
      ],
      "metadata": {
        "id": "LRu6B8hvJEDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 함수\n",
        "\n",
        "def train(train_dir,\n",
        "          config,\n",
        "          dataset_fn,\n",
        "          checkpoints_to_keep=5,\n",
        "          keep_checkpoint_every_n_hours=1,\n",
        "          num_steps=None,\n",
        "          master='',\n",
        "          num_sync_workers=0,\n",
        "          num_ps_tasks=0,\n",
        "          task=0):\n",
        "  \"\"\"Train loop.\"\"\"\n",
        "  # checkpoint 저장 경로\n",
        "  tf.gfile.MakeDirs(train_dir)\n",
        "  is_chief = (task == 0)\n",
        "  \"\"\"\n",
        "  if is_chief:\n",
        "    _trial_summary(\n",
        "        config.hparams, config.train_examples_path or config.tfds_name,\n",
        "        train_dir)\n",
        "  \"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    with tf.device(tf.train.replica_device_setter(\n",
        "        num_ps_tasks, merge_devices=True)):\n",
        "\n",
        "      model = config.model\n",
        "      model.build(config.hparams,\n",
        "                  config.data_converter.output_depth,\n",
        "                  is_training=True)\n",
        "      \n",
        "      # optimizer는 Adam을 사용\n",
        "      optimizer = model.train(**_get_input_tensors(dataset_fn(), config))\n",
        "\n",
        "      hooks = []\n",
        "      if num_sync_workers:\n",
        "        optimizer = tf.train.SyncReplicasOptimizer(\n",
        "            optimizer,\n",
        "            num_sync_workers)\n",
        "        hooks.append(optimizer.make_session_run_hook(is_chief))\n",
        "\n",
        "      grads, var_list = list(zip(*optimizer.compute_gradients(model.loss))) # 손실 함수는 Cross Entropy Loss를 사용\n",
        "\n",
        "      # global_norm을 수행 \n",
        "      global_norm = tf.global_norm(grads)\n",
        "      tf.summary.scalar('global_norm', global_norm)\n",
        "\n",
        "      if config.hparams.clip_mode == 'value':\n",
        "        g = config.hparams.grad_clip\n",
        "        clipped_grads = [tf.clip_by_value(grad, -g, g) for grad in grads]\n",
        "      elif config.hparams.clip_mode == 'global_norm':\n",
        "        clipped_grads = tf.cond(\n",
        "            global_norm < config.hparams.grad_norm_clip_to_zero,\n",
        "            lambda: tf.clip_by_global_norm(  # pylint:disable=g-long-lambda\n",
        "                grads, config.hparams.grad_clip, use_norm=global_norm)[0],\n",
        "            lambda: [tf.zeros(tf.shape(g)) for g in grads])\n",
        "      else:\n",
        "        raise ValueError(\n",
        "            'Unknown clip_mode: {}'.format(config.hparams.clip_mode))\n",
        "      train_op = optimizer.apply_gradients(\n",
        "          list(zip(clipped_grads, var_list)),\n",
        "          global_step=model.global_step,\n",
        "          name='train_step')\n",
        "\n",
        "      logging_dict = {'global_step': model.global_step,\n",
        "                      'loss': model.loss}\n",
        "\n",
        "      hooks.append(tf.train.LoggingTensorHook(logging_dict, every_n_iter=100))\n",
        "      if num_steps:\n",
        "        hooks.append(tf.train.StopAtStepHook(last_step=num_steps))\n",
        "\n",
        "      scaffold = tf.train.Scaffold(\n",
        "          saver=tf.train.Saver(\n",
        "              max_to_keep=checkpoints_to_keep,\n",
        "              keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours))\n",
        "      tf_slim.training.train(\n",
        "          train_op=train_op,\n",
        "          logdir=train_dir,\n",
        "          scaffold=scaffold,\n",
        "          hooks=hooks,\n",
        "          save_checkpoint_secs=60,\n",
        "          master=master,\n",
        "          is_chief=is_chief)"
      ],
      "metadata": {
        "id": "YPcJjFluJGk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(config_map,\n",
        "        tf_file_reader=tf.data.TFRecordDataset,\n",
        "        file_reader=tf.python_io.tf_record_iterator,):\n",
        "  \n",
        "  train_dir = '/content/train'\n",
        "  config = config_map['groovae_4bar']\n",
        "  def dataset_fn():\n",
        "    return data.get_dataset(\n",
        "        config,\n",
        "        tf_file_reader=tf_file_reader,\n",
        "        is_training=True,\n",
        "        cache_dataset=True)\n",
        "  \n",
        "  train(\n",
        "    train_dir,\n",
        "    config=config,\n",
        "    dataset_fn=dataset_fn,\n",
        "    keep_checkpoint_every_n_hours=1,\n",
        "    num_steps=100,\n",
        "    master='',\n",
        "    num_sync_workers=0,\n",
        "    num_ps_tasks=0,\n",
        "    task=0)\n",
        " \n",
        "\n",
        "run(CONFIG_MAP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QguRio3KJSJh",
        "outputId": "0e15353e-ea13-4288-9fa6-bab04c7d867a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:446: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:751: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  self._names[\"W\"], [input_size + self._num_units, self._num_units * 4])\n",
            "/usr/local/lib/python3.7/dist-packages/magenta/contrib/rnn.py:754: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  initializer=tf.constant_initializer(0.0))\n",
            "/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:199: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n",
            "/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/base_model.py:205: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Do not call `graph_parents`.\n",
            "/usr/local/lib/python3.7/dist-packages/magenta/models/music_vae/lstm_utils.py:99: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  name=name),\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:397: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1068: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Midi 파일 생성"
      ],
      "metadata": {
        "id": "KonLUCoL3Yje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "import note_seq\n",
        "\n",
        "model = TrainedModel(\n",
        "    config=CONFIG_MAP['groovae_4bar'],\n",
        "    batch_size=1,\n",
        "    checkpoint_dir_or_path='/content/train') \n",
        "\n",
        "# 4마디 샘플을 생성\n",
        "generated_sequence = model.sample(n=1, length=16*4, temperature=0.5)\n",
        "note_seq.sequence_proto_to_midi_file(generated_sequence[0], '/content/sample/4bar_sample.mid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4S_yWNKhilN",
        "outputId": "ed852f52-5e88-438a-e04c-8a0f0fc18cb5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
          ]
        }
      ]
    }
  ]
}